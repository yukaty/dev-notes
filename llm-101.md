# Intro to LLMs
Study note for Introduction to Large Language Models (LLMs) course on Codecademy

- [The Birth of AI](#the-birth-of-ai)
- [Detecting Patterns in Text](#detecting-patterns-in-text)
  - [Historical Background](#historical-background)
  - [Natural Language Processing (NLP)](#natural-language-processing-nlp)
  - [Tokens](#tokens)
  - [Language Models in NLP](#language-models-in-nlp)
  - [Next Word Prediction](#next-word-prediction)
  - [N-grams and Tokenization](#n-grams-and-tokenization)
    - [N-grams:](#n-grams)
    - [Tokenization:](#tokenization)
- [Autoregressive Language Models](#autoregressive-language-models)
  - [Language Models](#language-models)
  - [Corpus](#corpus)
  - [Count-based Language Models](#count-based-language-models)
- [Count-Based Autoregressive Language Models](#count-based-autoregressive-language-models)
  - [Step-by-Step Example](#step-by-step-example)
  - [Calculating Conditional Probability](#calculating-conditional-probability)
  - [Sentence Probability](#sentence-probability)
- [Generalization: From Count-Based to Neural Language Models](#generalization-from-count-based-to-neural-language-models)
  - [Problem with Count-Based Language Models](#problem-with-count-based-language-models)
  - [Generalization](#generalization)
  - [Moving Beyond Counting](#moving-beyond-counting)
  - [Word Embeddings](#word-embeddings)
  - [Neural Language Models](#neural-language-models)
- [Compression: Solving the Curse of Dimensionality](#compression-solving-the-curse-of-dimensionality)
  - [The Problem: Curse of Dimensionality](#the-problem-curse-of-dimensionality)
  - [Compression through Neural Language Models](#compression-through-neural-language-models)
  - [Information Loss](#information-loss)
- [Neural Networks and Language Models](#neural-networks-and-language-models)
  - [1. ELIZA and Symbolic AI](#1-eliza-and-symbolic-ai)
  - [2. Neural Networks and Subsymbolic AI](#2-neural-networks-and-subsymbolic-ai)
  - [The Rise of Deep Learning](#the-rise-of-deep-learning)
  - [The Birth of the Transformer](#the-birth-of-the-transformer)
- [LLMs: Caveats and Possibilities](#llms-caveats-and-possibilities)
  - [Large Language Models (LLMs) Overview](#large-language-models-llms-overview)
  - [Emergence in LLMs](#emergence-in-llms)
  - [Hallucinations in LLMs](#hallucinations-in-llms)
  - [LLMs and Factual Grounding](#llms-and-factual-grounding)
- [LLM Parameters: Temperature](#llm-parameters-temperature)
  - [What is Temperature in LLMs?](#what-is-temperature-in-llms)
  - [Low Temperature](#low-temperature)
  - [High Temperature](#high-temperature)
  - [Important Note on Temperature](#important-note-on-temperature)
- [Summary: Large Language Models (LLMs)](#summary-large-language-models-llms)
  - [Key Concepts of LLMs](#key-concepts-of-llms)

## The Birth of AI

- **ELIZA (1966):** An early chatbot using rule-based scripts for conversations, developed by MIT.
- **ChatGPT (2022):** Developed by OpenAI, ChatGPT uses advanced neural networks to generate text based on large datasets.
- **Turing Test (1950):** A test by Alan Turing to assess a machine's ability to mimic human behavior.

## Detecting Patterns in Text

### Historical Background
- **A.A. Markov (1913):** Modeled language patterns using probabilities.
- **Claude Shannon (1948):** Laid foundations for next-letter prediction models.

### Natural Language Processing (NLP)
- NLP is a field of artificial intelligence that focuses on the interaction between computers and human languages.
- Automating text pattern recognition and language understanding using computers.
- Requires transforming language into mathmatical form, typically by converting text into smaller units, called tokens.

### Tokens
Tokens are the smallest units of text in modern NLP. Depending on the model, a token could be:

- A word (e.g., "dog"),
- A subword (e.g., "ing" in "running"),
- Or even a single character.

### Language Models in NLP
- Language models are built to predict the next token in a sequence based on the tokens that have come before.
- These models are one of the tools to perform NLP tasks, such as text generation, translation, and question answering.

### Next Word Prediction
- Predicting the next token depends on patterns in language and context, such as grammar, syntax, and meaning.
- Example:
  - In a sentence involving "volcano," the word "erupt" is predicted due to its context.

### N-grams and Tokenization
Google n-gram Viewer: https://books.google.com/ngrams/

#### N-grams:
In the past, n-gram models were used to detect patterns in text by breaking it into sequences of "n" tokens. For example:
- Unigram: A single token (e.g., "dog"),
- Bigram: A two-token sequence (e.g., "the dog"),
- Trigram: A three-token sequence (e.g., "the dog barks").

#### Tokenization:
In modern NLP, tokenization is the process of breaking text into tokens, which are used as input for language models like GPT. There are different types of tokenization, such as word-level and subword-level tokenization.

**Example: Original sentence: "The volcano might erupt."**

- Word-level tokens (splitting by whole words):
  - ["The", "volcano", "might", "erupt", "."]
- Subword-level tokens (splitting words into smaller meaningful parts):
  - ["The", "vol", "cano", "might", "er", "upt", "."]

## Autoregressive Language Models
- **Autoregressive** refers to predicting future words based on past sequences stored in a corpus.
- These models predict the next word in a sequence by analyzing previously occurring words or phrases.

### Language Models
   - Language models aim to perform a wide variety of language tasks by predicting the next word or phrase in a sequence.
   - **Large language models (LLMs)** have the potential to exhibit behavior comparable to human thought processes.

### Corpus
   - The text data used to train language models, often gathered from books, articles, websites, and stored digitally, is referred to as a **corpus**.

### Count-based Language Models
   - Count-based Language Models estimate the probability of word sequences based on their frequency in a corpus. These models include methods like n-grams, which capture patterns of words in sequences.
   - A **lookup table** is used within the models to store word combinations and their frequencies. It helps the model calculate probabilities.

## Count-Based Autoregressive Language Models

Count-Based Autoregressive Language Models predict the likelihood of a sentence by breaking it down into individual words and calculating the probability of each word appearing, given the previous words in the sentence.

### Step-by-Step Example
Consider the sentence **`What do I say next?`** and how a count-based autoregressive model predicts the likelihood of this sentence appearing in a text corpus.

1. Predict the first word
   - How likely is it that the word "what" appears?

2. Predict the second word
   - After the word "what", how likely is the word "do" to appear? This is called **conditional probability**, represented as **P(do | what)**.

3. Predict the third word:
   - After the sequence "what do", how likely is the word "I" to appear? This is represented as **P(I | what do)**.

… and so on for each word in the sentence.

### Calculating Conditional Probability
Conditional probability is calculated by looking at how often a word sequence appears in the text corpus compared to other possible word sequences.

- Example:
  - From the text corpus, the sequence "what do" appears 40 times, while "what am" appears 16 times, "what should" 16 times, and "what have" 8 times.
  - So, the probability **P(do | what)** is calculated as:

  P(do | what) = 40 / (40 + 16 + 16 + 8) = 40 / 80 = 0.5

---
### Sentence Probability
The probability of the entire sentence "What do I say next?" appearing in the text is calculated by multiplying the individual conditional probabilities for each word:

  P(sentence) = P(what) * P(do | what) * P(I | what do) * P(say | what do I) * P(next | what do I say)

This is how a count-based autoregressive language model predicts the likelihood of a sentence appearing in a given text corpus.

---
## Generalization: From Count-Based to Neural Language Models

Shifting from count-based models to neural language models with word embeddings is crucial for enabling models to generate more sophisticated and contextually appropriate text.

### Problem with Count-Based Language Models
- Count-based models assign probabilities to sentences based on how often words or sequences of words appear in the training text.
- If a sentence never appears in the training text, it is assigned **zero probability** (i.e., the model believes it is impossible).

- Example:
  - The sentence "A lion is chasing a llama" may not appear in most texts because lions and llamas exist on different continents. However, it’s still possible for such a scenario to happen in some hypothetical context.
  - A count-based model would incorrectly assign **zero probability** to this sentence if it was never seen during training.

---
### Generalization
- **Generalization** refers to a model’s ability to adapt and handle unseen data.
- Count-based models lack generalization because they rely solely on occurrences in the training data, limiting their ability to generate meaningful text when encountering new word combinations.

---
### Moving Beyond Counting
- To improve generalization, we move from counting words to understanding their **meaning and context**. This is called **semantic understanding**.

- Example:
  - A more sophisticated model understands that "lions" are predators and "llamas" are domesticated prey-like animals, and thus assigns a **non-zero probability** (it is possible) for a lion chasing a llama, even if this combination was not in the training text.

---
### Word Embeddings
- **Word Embeddings** are mathematical representations (word vectors) that capture the meaning and context of words.
- **Word vectors** are numbers that place words in a semantic space, where words with similar meanings are located near each other.

  **Benefits:**
  - Allows models to differentiate between words with the same spelling but different meanings (homonyms).
  - Example: The word "lead" in “lead the team” vs. "lead" in “lead pipe” is understood in context.

---
### Neural Language Models
- **Neural Networks** are used to generate word embeddings and build more generalizable language models.
- These models, called **Neural Language Models**, are better at predicting and generating text based on the meaning of words rather than just counting their occurrences.

## Compression: Solving the Curse of Dimensionality

- **Compression** and **generalization** go hand in hand in neural language models.
  - **Compression** may lead to zero probabilities for some existing text.
  - **Generalization** allows the model to assign non-zero probabilities to unseen text.

In essence, these two processes are two sides of the same coin!

### The Problem: Curse of Dimensionality
- **Count-based language models** run into an issue called the **curse of dimensionality**, which refers to the rapid growth in the size of the count table as the text corpus gets larger.

---
### Compression through Neural Language Models
- **Neural language models** solve this problem by **compressing the text** into a smaller set of parameters, often called **weights**.
- Instead of building a huge count table, neural language models try to **approximate** the table, learning patterns and relationships between words.

  **Analogy:**
  - Imagine reducing a high-resolution photo to a low-resolution version. The reduced version is smaller and easier to store, but it still retains important features. The quality of compression depends on how well the key features are preserved!

---
### Information Loss
- **Yes, there is some information loss** during compression. Neural language models may sometimes assign **zero probability** to text that actually exists in the corpus.
- However, the **benefit** is that the model can **generalize** to produce new, unseen text by making semantic connections.

---

## Neural Networks and Language Models

### 1. ELIZA and Symbolic AI
- **ELIZA** (created in the 1960s) is an early example of **symbolic AI**, which tried to model human thinking using **rule-based systems**.
- **Symbolic AI** uses **explicit rules** and **mathematical logic** to simulate thought processes.

---
### 2. Neural Networks and Subsymbolic AI
- In contrast to symbolic AI, **subsymbolic AI** emerged from the idea that many human cognitive processes are **unconscious** and can’t be captured by explicit rules.
- **Neural networks** were inspired by neuroscience. In 1958, psychologist **Frank Rosenblatt** created the **perceptron**, a simple computational model that mimics a neuron.
- By connecting multiple perceptrons, researchers believed they could create an intelligent information-processing system similar to the human brain.

---
### The Rise of Deep Learning
- Neural networks went through phases of popularity over the years, but saw a resurgence in the early 2000s with the rise of **big data** and increased computing power.
- **Machine learning** is a set of algorithms that **learn patterns** from large datasets to perform tasks like prediction and generation. Neural networks can be:
  - **Shallow:** Few layers of processing units (neurons).
  - **Deep:** Many layers, leading to the term **deep learning**.

---
### The Birth of the Transformer
- Different neural networks are arranged in specific **architectures** to perform certain tasks:
  - **Convolutional Neural Networks (CNNs)** are excellent for image processing.
  - **Recurrent Neural Networks (RNNs)** are suited for **sequential data** like language and are used in **natural language processing (NLP)** tasks such as translation and speech recognition.
- In **2017**, a new architecture called the **transformer** emerged, revolutionizing NLP tasks.
  - **Transformers** are the basis for **Generative Pre-trained Transformers (GPTs)**, which are **Large Language Models (LLMs)** capable of generating human-like text by learning from vast amounts of text data.


## LLMs: Caveats and Possibilities
### Large Language Models (LLMs) Overview
- **Large language models (LLMs)**, such as GPT, work similarly to smaller models but have some key differences due to their size and complexity. Here’s a recap of essential concepts:

  - **Training data**: LLMs require large text corpora, and their output is influenced by the content in this data.
  - **Task**: The main task of a language model is to **predict the next word** (or token) based on previous words.
  - **Probability distributions**: These are used to predict words, and they are learned through neural networks.
  - **Embeddings**: Neural networks convert text into mathematical representations (embeddings) that preserve word meaning and context.
  - **Generalization and compression**: LLMs compress their training data into a more manageable representation, which allows them to generalize and generate unseen text. However, this compression may also result in **information loss**.

---
### Emergence in LLMs
- **Emergence** refers to the sudden improvement in model capabilities as they grow larger.
  - This concept, drawn from physics, means that when a system reaches a certain size, **qualitative changes** occur in its behavior.
  - In LLMs, emergence can manifest in **sophisticated abilities**, such as explaining jokes, creating poetry, or mimicking an author’s style. These abilities arise even though the model wasn’t specifically trained for them.
  - This has led some to speculate about the potential for **Artificial General Intelligence (AGI)**.

---
### Hallucinations in LLMs
- **Hallucinations** refer to situations where LLMs generate **incorrect or erroneous text**. Since LLMs can generate text that has never been seen before, there’s no way to verify whether it’s true or factual.
  - This happens because the model generalizes based on patterns, filling in gaps with the most likely or plausible response.
  - **Factual grounding** is a challenge for LLMs, as they rely on the accuracy of their training data and lack the ability to independently verify information.

---
### LLMs and Factual Grounding
- LLMs cannot distinguish between **fact and fiction** on their own. If a piece of information is missing from their training data, they might **make up information** that sounds plausible but could be wrong.
  - Even though models like GPT-4 use **human feedback** to reduce errors and minimize hallucinations, **hallucinations cannot be fully eliminated** due to the way LLMs are built.
  - The issue is further complicated by **compression**, which can cause information loss and make it harder for LLMs to retain all relevant data.


## LLM Parameters: Temperature

---
### What is Temperature in LLMs?
- **Temperature** is a parameter in **large language models (LLMs)** that controls the **sharpness** of the **probability distribution** used to generate text.
- It influences the **likelihood** of words being selected in text generation. Adjusting temperature can make the model’s output either more predictable or more creative.

--
### Low Temperature
- **Low temperature** makes the probability distribution **narrower**, which means:
  - Higher-probability words become even more likely to be selected.
  - Lower-probability words become less likely to appear.
  - This leads to more **deterministic outputs**—the model tends to generate the same response each time.

---
### High Temperature
- **High temperature** makes the probability distribution **wider**, which means:
  - Lower-probability words are given a higher chance of being selected.
  - This increases the **creativity** or **randomness** of the model’s output.
  - This setting is often used to get more **novel or amusing outcomes**.

---

### Important Note on Temperature
- **Temperature** does not guarantee factual accuracy. Even if a model produces a highly probable word or phrase, it doesn’t mean that the output is factually correct.
- **Low temperature** results in more consistent outputs, but that doesn’t necessarily mean the information is accurate.
- Other parameters in LLMs, like frequency and sampling, can also be adjusted to fine-tune output behavior.



## Summary: Large Language Models (LLMs)

LLMs are the core technology behind recent advancements in **Natural Language Processing (NLP)**. Popular examples of LLMs include **GPT**, **PaLM**, **Llama**, and **BLOOM**. These are foundational models on which specific applications, like ChatGPT and Google’s Bard (built on PaLM), are developed.

---

### Key Concepts of LLMs

1. **Language Models:**
   - Language models are trained on large text corpora to perform various tasks like text generation, summarization, and translation.
   - **LLMs** are enhanced by using **neural networks** to learn the relationships between words in text.

2. **Transformers and Neural Networks:**
   - The rise of LLMs is due to the highly efficient neural network architecture called the **transformer**, which addresses problems like generalization and the curse of dimensionality.
   - Text is compressed into mathematical representations, making the models powerful and able to generalize to unseen data.

3. **Compression and Generalization:**
   - LLMs rely on **compression** (reducing data complexity) and **generalization** (ability to generate novel text) to exhibit advanced abilities like creativity.
   - However, generative models may lack **factual grounding**, meaning their outputs might not always be accurate.

4. **Autoregressive Models and Probability:**
   - Autoregressive models, whether count-based or neural, generate text by predicting the next word based on probability distributions.
   - **Temperature** is a key parameter in LLMs that controls how **deterministic** or **creative** the model’s output is.